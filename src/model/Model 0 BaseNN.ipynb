{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zn5U4EE6K86v",
    "outputId": "42015c25-1d87-42a3-950f-a749fc038a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "2.3.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "!pip install torch\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHSP6-RBOqCE",
    "outputId": "d009a495-53a0-4443-e489-88745d51e9e9"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import pickle\n",
    "# from torch_geometric.datasets import TUDataset\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# FOLDERNAME = 'cse493g1/project/data'\n",
    "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# %cd drive/My\\ Drive\n",
    "\n",
    "# dataset_path = os.path.join(FOLDERNAME, 'solutions_dataset_gnn_graphs.pkl')\n",
    "# with open(dataset_path, 'rb') as f:\n",
    "#     dataset = pickle.load(f)\n",
    "\n",
    "from construct_gnn_dataset import SolutionDataset\n",
    "\n",
    "dataset = SolutionDataset(root='../../data/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: SolutionDataset(5000):\n",
      "====================\n",
      "Number of graphs: 5000\n",
      "Number of features: 139\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "# print(f'Number of classes: {dataset.num_classes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printstats(index):\n",
    "    data = dataset[index]  \n",
    "\n",
    "    print()\n",
    "    print(data)\n",
    "    print('=============================================================')\n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {data.has_self_loops()}')\n",
    "    print(f'Is undirected: {data.is_undirected()}')\n",
    "    print('=============================================================')\n",
    "    print(f'Data.x: {data.x}')\n",
    "    print(f'Data.y: {data.y}')\n",
    "\n",
    "    return (data.x, data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data(edge_index=[2, 165], name=[166], cooccurrences=[166, 139], num_nodes=166, x=[166, 139], y=[10])\n",
      "=============================================================\n",
      "Number of nodes: 166\n",
      "Number of edges: 165\n",
      "Average node degree: 0.99\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n",
      "=============================================================\n",
      "Data.x: tensor([[-0.1187, -0.1187, -0.1187,  ..., -0.1187, -0.1187, -0.1187],\n",
      "        [-0.1707, -0.1707, -0.1707,  ..., -0.1707, -0.1707, -0.1707],\n",
      "        [-0.1231, -0.1231, -0.1231,  ..., -0.1231, -0.1231, -0.1231],\n",
      "        ...,\n",
      "        [-0.1231, -0.1231, -0.1231,  ..., -0.1231, -0.1231, -0.1231],\n",
      "        [-0.1515, -0.1515,  0.9832,  ...,  0.1190, -0.0980, -0.1515],\n",
      "        [-0.1231, -0.1231, -0.1231,  ..., -0.1231, -0.1231, -0.1231]])\n",
      "Data.y: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "Data(edge_index=[2, 238], name=[239], cooccurrences=[239, 139], num_nodes=239, x=[239, 139], y=[10])\n",
      "=============================================================\n",
      "Number of nodes: 239\n",
      "Number of edges: 238\n",
      "Average node degree: 1.00\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n",
      "=============================================================\n",
      "Data.x: tensor([[-0.1187, -0.1187, -0.1187,  ..., -0.1187, -0.1187, -0.1187],\n",
      "        [-0.1707, -0.1707, -0.1707,  ..., -0.1707, -0.1707, -0.1707],\n",
      "        [-0.1231, -0.1231, -0.1231,  ..., -0.1231, -0.1231, -0.1231],\n",
      "        ...,\n",
      "        [-0.1529, -0.1529,  0.0658,  ..., -0.1525, -0.1529, -0.1529],\n",
      "        [-0.1515, -0.1515,  0.9832,  ...,  0.1190, -0.0980, -0.1515],\n",
      "        [-0.1231, -0.1231, -0.1231,  ..., -0.1231, -0.1231, -0.1231]])\n",
      "Data.y: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "x1, y1 = printstats(0)\n",
    "x2, y2 = printstats(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "NODE_FEATURES = dataset.num_features\n",
    "NUM_CLASSES = dataset[0].y.size(-1)\n",
    "\n",
    "print(NODE_FEATURES)\n",
    "print(NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j11WiUr-PRH_",
    "outputId": "249ad901-3912-41e0-b193-0caad823ddd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 4500\n",
      "Number of test graphs: 500\n"
     ]
    }
   ],
   "source": [
    "assert (len(dataset) % 10 == 0)\n",
    "split = (len(dataset) * 9) // 10\n",
    "\n",
    "train_dataset = [item for i, item in enumerate(dataset) if (i + 1) % 10 != 0]\n",
    "test_dataset = [item for i, item in enumerate(dataset) if (i + 1) % 10 == 0]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gZ-l0npPIca",
    "outputId": "29e5d503-5ac7-4e87-b93a-8f28d0498e1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(edge_index=[2, 147], name=[1], cooccurrences=[148, 139], num_nodes=148, x=[148, 139], y=[10], batch=[148], ptr=[2])\n",
      "\n",
      "Step 2500:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(edge_index=[2, 141], name=[1], cooccurrences=[142, 139], num_nodes=142, x=[142, 139], y=[10], batch=[142], ptr=[2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    data = data.to(device)\n",
    "    \n",
    "    if (step) % 2500 == 0:\n",
    "        print(f'Step {step}:')\n",
    "        print('=======')\n",
    "        print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "        print(data)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CN3sRVuaQ88l",
    "outputId": "0cdb6a09-f403-42b4-ec85-d019d3f18936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNN(\n",
      "  (lin1): Linear(in_features=139, out_features=250, bias=True)\n",
      "  (lin2): Linear(in_features=250, out_features=250, bias=True)\n",
      "  (lin3): Linear(in_features=250, out_features=250, bias=True)\n",
      "  (lin4): Linear(in_features=250, out_features=250, bias=True)\n",
      "  (lin5): Linear(in_features=250, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class FCNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.lin1 = Linear(NODE_FEATURES, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin4 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin5 = Linear(hidden_channels, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin3(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin4(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin5(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = FCNN(hidden_channels=250).to(device) \n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "V2Q37tbHyQ6A"
   },
   "source": [
    "Here, we again make use of the [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv) with $\\mathrm{ReLU}(x) = \\max(x, 0)$ activation for obtaining localized node embeddings, before we apply our final classifier on top of a graph readout layer.\n",
    "\n",
    "Let's train our network for a few epochs to see how well it performs on the training as well as test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 Progress:   0%|          | 0/4500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([99, 10])\n",
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (99) to match target batch_size (1).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(yTrue\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 21\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myTrue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages/torch/nn/modules/loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CSE493G1/lib/python3.10/site-packages/torch/nn/functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (99) to match target batch_size (1)."
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epoch_losses = {}\n",
    "epoch_accuracies = {}\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} Progress\"):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x)\n",
    "        yTrue = batch.y.float().reshape(1, 10)\n",
    "        print(out.shape)\n",
    "        print(yTrue.shape)\n",
    "        loss = criterion(out, yTrue)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        _, predicted = torch.max(out, dim=1)  \n",
    "        correct += (predicted == yTrue).sum().item()\n",
    "        total += batch.y.size(0)\n",
    "    \n",
    "    epoch_accuracy = correct / total\n",
    "    epoch_losses[epoch + 1] = epoch_loss\n",
    "    epoch_accuracies[epoch + 1] = epoch_accuracy\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"GCNModel.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load(MODEL_PATH)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing Progress\"):\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch.x, batch.edge_index, batch.batch)  # Forward pass            \n",
    "            _, predicted = torch.max(out, 0)  # Get the index of the max log-probability\n",
    "            total += batch.y.size(0)  # Total number of graphs\n",
    "            correct += (predicted == batch.y).sum().item()  # Correct predictions\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "test_accuracy = test(loaded_model, test_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CSE493G1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
